{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors, Support Vector Machines, and Naive Bayes\n",
    "\n",
    "## Agenda. \n",
    "\n",
    "- Overview Support Vector Machines.  \n",
    "- Overview of K-NN.  \n",
    "- Naive Bayes.  \n",
    "- Comparison on SPAM with logistic regression, SVM, KNN, and naive bayes.    \n",
    "\n",
    "## Resources\n",
    "[Raschka's Naive Bayes Paper](https://arxiv.org/pdf/1410.5329.pdf)\n",
    "<br>[SVM-rank](https://www.cs.cornell.edu/people/tj/svm_light/svm_rank.html)\n",
    "<br>[A Tutorial on Support Vector Machines for Pattern Recognition](https://www.microsoft.com/en-us/research/publication/a-tutorial-on-support-vector-machines-for-pattern-recognition/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms Discussed so Far\n",
    "- Linear Regression  \n",
    "- Lasso/Ridge Regression  \n",
    "- Logistic Regression  \n",
    "- Decision Trees  \n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Foundational Supervised Learning Algorithms\n",
    "- [Support Vector Machines](https://en.wikipedia.org/wiki/Support-vector_machine).  \n",
    "- [k-Nearest Neighbors](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm).  \n",
    "- [Naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier).  \n",
    "\n",
    "[Support vector machines and k-nearest neighbors are overviewed in Machine Learning with Python 3rd Edition, Chapter 3.](https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch03)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)\n",
    "\n",
    "<img src='./diagrams/svm-margin.png' style=\"width: 500px\">\n",
    "\n",
    "[Image source: Python Machine Learning 3rd Edition, Figure 3.9](https://github.com/rasbt/python-machine-learning-book-3rd-edition/blob/master/ch03/images/03_09.png)\n",
    "\n",
    "So far for classification we have talked about:\n",
    "- Logistic Regression. \n",
    "- Decision Trees.  \n",
    "Both of those are models that produce linear or linear-hinge decision functions.\n",
    "> Logistic regression is a linear model that learns coefficient weights and normalizes the output with a sigmoid (or softmax) function.  \n",
    "<br><br>Decision trees learn rules that are effectively a series of if-else statements.\n",
    "\n",
    "### Hyperplanes\n",
    "- Assume a two-class classification problem with two predictors X1 and X2.  \n",
    "- Assume the two classes are “linearly separable” i.e. one can draw a straight line in which all points on one side belong to the first class and points on the other side to the second class.    \n",
    "- Then a natural approach is to find the straight line that gives the biggest separation between the classes i.e. the points are as far from the line as possible.  \n",
    "- This is the basic idea of a support vector classifier.  \n",
    "\n",
    "**What if we encountered a different type of data that is inherently non-linear?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Modified from: \n",
    "https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "names = [\"Logistic Regression\", \"Decision Tree\", \"SVM\"]\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    SVC(kernel='rbf')\n",
    "    ]\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1\n",
    "                          )\n",
    "\n",
    "datasets = [make_moons(noise=0, random_state=0),\n",
    "            make_circles(noise=0, factor=0.7, random_state=1),\n",
    "            ]\n",
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Input data\")\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "               edgecolors='k')\n",
    "    # Plot the testing points\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n",
    "               edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        # Plot the decision boundary. For that, we will assign a color to each\n",
    "        # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "        # Plot the training points\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "                   edgecolors='k')\n",
    "        # Plot the testing points\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "                   edgecolors='k', alpha=0.6)\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name)\n",
    "        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                size=15, horizontalalignment='right')\n",
    "        i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a SVM?\n",
    "It views every feature in high-dimensional space. For the above example, that would be two-dimensional, but if your feature matrix had 10,000 features, it would see the world in a space with 10,000 dimensions.\n",
    "\n",
    "It \"draws\" lines to create hyperplanes that attempt to maximize the separation or margin of the classes. You traditionally have to label the negative classes in $y$ as $-1$ and the positive classes as $1$.\n",
    "\n",
    "It can be represented by: \n",
    "$$wx - b = 0$$  \n",
    "$wx = w^{(1)}x^{(1)}+w^{(2)}x^{(2)}+\\dots+w^{(D)}x^{(D)}$, where $D$ is the number of dimensions in the feature vector $x$.\n",
    "\n",
    "And predicts the class with $y=sign(wx-b)$, where $y\\in(-1,1)$\n",
    "\n",
    "This is solved by optimizing these constraints:\n",
    "$$\n",
    "wx_{i}-b\\geq+1 \\space \\text{if} \\space y_{i}=+1\n",
    "$$\n",
    "$$\n",
    "wx_{i}-b\\leq-1 \\space \\text{if} \\space y_{i}=-1\n",
    "$$\n",
    "\n",
    "We want it to separate the positive from the negatives by the largest margin, which is the decision boundary (see chart above). To determine the margin, we use `distance`. This is generally done with minimizing the Euclidean:\n",
    "$$\n",
    "||w||=\\sqrt{\\sum(w^{{j}})^2}\n",
    "$$\n",
    "\n",
    "We'll minimize $||w||$, with respect $y_{i}(wx_{i}-b)\\geq+1$, which is shorthand for the above two constraints. The smaller the $||w||$, the larger the distance between the hyperplanes.\n",
    "\n",
    "> The positive examples should fall on one side of the hyperplance and the negative examples should fall on the other.\n",
    "\n",
    "The distance between hyperplanes is $\\frac{2}{||w||}$, i.e., smaller $||w||$ is larger distance.\n",
    "\n",
    "#### Hard vs. soft margin\n",
    "The above assumes the two classes are completely linearly separated - which generally won't be the class in reality (hard margin).\n",
    "\n",
    "> Practical implementation use a soft margin, which introduces a slack variable, $\\epsilon$. This causes the objection function to become:\n",
    "\n",
    "$$\n",
    "\\frac{2}{||w||}+C(\\sum \\epsilon^{i})\n",
    "$$\n",
    "\n",
    "$C$ is the way we can use regularization with SVMs.\n",
    "\n",
    "<img src='./diagrams/svm-c.png' style='width: 500px'>\n",
    "\n",
    "[Image source: Python Machine Learning 3rd Edition, Figure 3.10](https://github.com/rasbt/python-machine-learning-book-3rd-edition/blob/master/ch03/images/03_10.png)\n",
    "\n",
    "> Higher $C$ decreases the margin and smaller values increase the margin. Smaller $C$ creates a simpler model since the boundaries are much wider.\n",
    "\n",
    "#### Compared to Logistic Regression\n",
    "Logistic regression and linear SVMs are very similar and will generally more or less match each other's performance. Defer to logistic regression, since it is a simplier model in that case.  \n",
    "\n",
    "### Kernel Trick\n",
    "While SVMs are essentially linear models, we can use the kernel trick to make these models work well on non-linear data. Here we transform our space from two-dimensions to three-dimensions.\n",
    "\n",
    "$$\n",
    "\\phi(x_1,x_2)=(z_1,z_2,z_3)=(x_1,x_2,x_{1}^{2},x_{2}^{2})\n",
    "$$\n",
    "\n",
    "Which is linearly separable:\n",
    "\n",
    "<img src='./diagrams/svm-kernel.png' style='width: 500px'>\n",
    "\n",
    "[Image source: Python Machine Learning 3rd Edition, Figure 3.13](https://github.com/rasbt/python-machine-learning-book-3rd-edition/blob/master/ch03/images/03_13.png)\n",
    "\n",
    "> $\\phi$ is an arbitrary transformation function.\n",
    "\n",
    "The most common is the radial basis function (which essentially a similarity function):\n",
    "\n",
    "$$\n",
    "k(x^{(i)},x^{(j)})=exp(-\\frac{||x^{(i)}-x^{(j)}||^2}{2\\sigma^2})\n",
    "$$\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Caution: </b> While powerful, these are VERY computationally intensive. Using on large datasets will be very expensive. </div>\n",
    "\n",
    "#### More information on SVMs:\n",
    "- [A Tutorial on Support Vector Machines for Pattern Recognition](https://www.microsoft.com/en-us/research/publication/a-tutorial-on-support-vector-machines-for-pattern-recognition/)  \n",
    "- [scikit-learn Documentation](https://scikit-learn.org/stable/modules/svm.html#svm-classification)\n",
    "\n",
    "Some of the different kernels available:\n",
    "<img src='./diagrams/svm-kernels.png' style='width: 500px'>\n",
    "\n",
    "[Image source: scikit-learn](https://scikit-learn.org/stable/modules/svm.html#svm-classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Example versus Logistic Regression\n",
    "[Compare performance on the digits dataset](https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "digits = load_digits()\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pd.Series(digits.target).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Almost perfectly balanced, multi-class dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Still need to split off the data for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_splits(X, y):\n",
    "    return train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "dX_train, dX_test, dy_train, dy_test = create_splits(digits.data, digits.target)\n",
    "\n",
    "print(f'Training sample: {dX_train.shape[0]:,}')\n",
    "print(f'Test sample: {dX_test.shape[0]:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "- We'll test using a few different regularization levels.  \n",
    "- Labels are balanced, so accuracy is a reasonable choice for a metric.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "lg_reg = modeling_pipeline = Pipeline([('scaling', StandardScaler()),\n",
    "                                       ('model', LogisticRegression(solver='liblinear'))])\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "  {'model__C': [0.01, 0.1, 1, 10, 100, 1000]}\n",
    " ]\n",
    "\n",
    "lg_results = GridSearchCV(estimator=lg_reg, param_grid=param_grid, scoring='accuracy', refit=True, cv=5)\n",
    "lg_results = lg_results.fit(dX_train, dy_train)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(lg_results, dX_test, dy_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_results.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine\n",
    "We'll try using a few different regularization options and two different kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "svm_m = modeling_pipeline = Pipeline([('scaling', StandardScaler()),\n",
    "                                       ('model', SVC())])\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "  {'model__C': [0.01, 0.1, 1, 10, 100, 1000], 'model__kernel': ['linear','rbf']}\n",
    " ]\n",
    "\n",
    "svm_results = GridSearchCV(estimator=svm_m, param_grid=param_grid, scoring='accuracy', refit=True, cv=5)\n",
    "svm_results = svm_results.fit(dX_train, dy_train)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(svm_results, dX_test, dy_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_score = svm_results.score(dX_test, dy_test)\n",
    "lreg_score = lg_results.score(dX_test, dy_test)\n",
    "\n",
    "print(f'Logistic Regression Score: {lreg_score:.2%}')\n",
    "print(f'Support Vector Machine Score: {svm_score:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Marginally better performance with the Support Vector Machine, with the below hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_results.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Support vector machines also work with regression problems](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR), but you may come across computational issues with larger datasets.\n",
    "\n",
    "> Support vector machines are commonly used for ranking problems, see [SVM-rank](https://www.cs.cornell.edu/people/tj/svm_light/svm_rank.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors ([KNN](https://scikit-learn.org/stable/modules/neighbors.html#classification))\n",
    "- It's a lazy algorithm. \n",
    "    - It doesn't want to learn anything.  \n",
    "    - It just tries to memorize what's it has seen before.  \n",
    "- It doesn't learn a decision function like logistic regression or SVM.  \n",
    "- There are no weights.  \n",
    "- There are no learned rules like in decision trees.  \n",
    "\n",
    "> KNN literally holds all the data in memory and determines what which points are closest to the test data.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Caution: </b> Since all the data will need to be loaded/reloaded into memory, this may not be recommended for larger datasets. </div>\n",
    "\n",
    "\n",
    "> If you trained a 10gb dataset, the model will would to load the 10gb dataset for each scoring run!\n",
    "\n",
    "### What's this is thing?\n",
    "- Non-parametric model since there are no parameters that are being learned (e.g., no regression weights).  \n",
    "- KNN is an instance-based learning model, since it memorizes the training data.  \n",
    "- KNN is lazy since it doesn't have a cost function.  \n",
    "\n",
    "### What is it doing?\n",
    "- Choose the number of closest samples, $k$, to look at based on a distance matrix.  \n",
    "- Find the k-nearest neighbors and assign the label based on the majority vote.  \n",
    "- scikit-learn has options to use [search trees](https://dl.acm.org/doi/10.1145/361002.361007) to speed up the algorithm, otherwise, the brute force approach will calculate each potential distance between each pair of points, which explodes in computation as $N$ grows.\n",
    "\n",
    "<img src='./diagrams/knn.png' style='width: 500px'>\n",
    "\n",
    "[Image source: Python Machine Learning 3rd Edition, Figure 3.23](https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch03/images)\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Benefit: </b> Immediately adapts as we get new training data. </div>\n",
    "\n",
    "\n",
    "### Biggest Hyperparameters\n",
    "- $k$\n",
    "- Distance function\n",
    "\n",
    "#### $k$\n",
    "- Critical for determining balance between under and overfitting.  \n",
    "- Smaller values of $k$ are more likely to lead to overfitting.  \n",
    "- You'll need to search the space to determine the best $k$ to use.  \n",
    "\n",
    "#### Distance \n",
    "- Used to determine how close the training samples are from the test examples.  \n",
    "- Euclidean is a common choice:  \n",
    "\n",
    "$$\\sqrt{\\sum((x - y)^2)}$$\n",
    "\n",
    "- [Minkowski](https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/minkdist.htm) is also another common choice:  \n",
    "$$\n",
    "d(x^{(i)},x^{(j)})=^p\\sqrt{\\sum{|x_{k}^{(i)}-x_{k}^{(j)}}|^p}\n",
    "$$\n",
    "\n",
    "$p=2$ is the same as Euclidean and $p=1$ is the same as Manhattan.\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Curse of Dimensionality: </b> Very susceptible to overfitting. The closest neighbors may be too far away in high-dimensional space to be good candidates. </div>\n",
    "\n",
    "- KNN doesn't have regularization, so you'll need to do feature selection and/or dimensionality reduction.  \n",
    "- Like SVM, works for classification and regression.\n",
    "- Regression can give you stairstep like results:  \n",
    "<img src='./diagrams/knn-reg.png' stype='width: 500px'>\n",
    "\n",
    "[Image source scikit-learn](https://scikit-learn.org/stable/auto_examples/neighbors/plot_regression.html#sphx-glr-auto-examples-neighbors-plot-regression-py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN on the Digits Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "knn_m = modeling_pipeline = Pipeline([('scaling', StandardScaler()),\n",
    "                                       ('model', KNeighborsClassifier())])\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "  {'model__n_neighbors': [1, 4, 8, 10, 15], 'model__weights': ['uniform','distance']}\n",
    " ]\n",
    "\n",
    "knn_results = GridSearchCV(estimator=knn_m, param_grid=param_grid, scoring='accuracy', refit=True, cv=5)\n",
    "knn_results = knn_results.fit(dX_train, dy_train)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(knn_results, dX_test, dy_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_score = svm_results.score(dX_test, dy_test)\n",
    "lreg_score = lg_results.score(dX_test, dy_test)\n",
    "knn_score = knn_results.score(dX_test, dy_test)\n",
    "\n",
    "print(f'Logistic Regression Score: {lreg_score:.2%}')\n",
    "print(f'Support Vector Machine Score: {svm_score:.2%}')\n",
    "print(f'k-Nearest Neighbor Score: {knn_score:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "A popular classifer for text classification problems (e.g., spam detection). Raschka has a paper on the details,[Naive Bayes and Text Classification I - Introduction and Theory](https://arxiv.org/abs/1410.5329).\n",
    "\n",
    "Based on Bayes Theorm:\n",
    "$$\n",
    "P(A|B)=\\frac{P(B|A)P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- A and B are events and $B\\neq0$  \n",
    "- A and B are independent events\n",
    "\n",
    "\"Naive\" comes from the independent assumption because it is unrealistic and largely ignored in reality.  \n",
    "- The stronger the independence violation the weaker the results (generally).\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Performance: </b> Generally compare well to other classifier in smaller datasets, but under-perform as $N$ grows. </div>\n",
    "\n",
    "### Mechanics\n",
    "Posterior Probability:\n",
    "$$\n",
    "P(w_j|x_i)=\\frac{P(x_i|w_j)P(w_j)}{P(x_i)}\n",
    "$$\n",
    "\n",
    "Predicted Label = $argmax(P(w_j|x_i)$, e.g., person has diabetes if $P(diabetes|x)\\geq P(no \\space diabetes|x)$\n",
    "\n",
    "More generally:\n",
    "$$\n",
    "P(x|w_j)=\\prod P(x_k|w_j)\n",
    "$$\n",
    "\n",
    "For categorical data, this resolves to frequency counts:\n",
    "$$\n",
    "\\hat{P}(x_i,w_i)=\\frac{N_{x_i,w_i}}{N_{w_j}}\n",
    "$$\n",
    "\n",
    "Where $N_{x_i,w_i}=$ the number of times $x_i$ appears and $N_{w_j}=$ the total counts.\n",
    "\n",
    "\n",
    "> Negative numbers: Because of the above, number numbers aren't allowed in the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "nb_m = modeling_pipeline = Pipeline([('model', MultinomialNB())])\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "  {'model__alpha': [0.1, 1]}\n",
    " ]\n",
    "\n",
    "nb_results = GridSearchCV(estimator=nb_m, param_grid=param_grid, scoring='accuracy', refit=True, cv=5)\n",
    "nb_results = nb_results.fit(dX_train, dy_train)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(nb_results, dX_test, dy_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_score = svm_results.score(dX_test, dy_test)\n",
    "lreg_score = lg_results.score(dX_test, dy_test)\n",
    "knn_score = knn_results.score(dX_test, dy_test)\n",
    "nb_score = nb_results.score(dX_test, dy_test)\n",
    "\n",
    "print(f'Logistic Regression Score: {lreg_score:.2%}')\n",
    "print(f'Support Vector Machine Score: {svm_score:.2%}')\n",
    "print(f'k-Nearest Neighbor Score: {knn_score:.2%}')\n",
    "print(f'Naive Bayes Score: {nb_score:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Naive Bayes had the worst performance on the digits. Required different processing since it can't handle negative values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about another example?\n",
    "### Spam Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/msaricaumbc/DS_data/master/ds602/week3/spam.csv', encoding='latin-1')\n",
    "df = df.iloc[:, :2]\n",
    "df.columns = ['label', 'message']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts().plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Unbalanced dataset, so we could consider a couple of things:\n",
    "- Look at either recall, precision, or F1.  \n",
    "- Look at weighting the classes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = np.where(df['label'] == 'spam', 1, 0)\n",
    "\n",
    "sX_train, sX_test, sy_train, sy_test = create_splits(df['message'], lab)\n",
    "\n",
    "print(f'Training examples: {sX_train.shape[0]:,}')\n",
    "print(f'Test examples: {sX_test.shape[0]:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a helper pipeline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(1,3), max_features=10000, stop_words='english')\n",
    "m = vect.fit_transform(sX_train)\n",
    "m\n",
    "\n",
    "df = pd.DataFrame(m.toarray(), columns=vect.get_feature_names_out())\n",
    "\n",
    "# df['û_thanks']\n",
    "# vect.get_feature_names_out()[::5]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vect.get_feature_names_out()[::15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def model_pipe(model, vectorizer, scale=False):\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    mp = Pipeline([('vectorizer', vectorizer), ('model', model)])\n",
    "    return mp\n",
    "\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words model\n",
    "- Going to vary some of the settings in the CountVectorizer and hyperparameters in the models.  \n",
    "- KNN and Naive Bayes don't support class weights.  \n",
    "    - We could try oversampling, but then we would need to manually construct the GridSearchCV algorithm to perform training on an oversampled dataset and validation/test evaluation on the nominal distribution.\n",
    "\n",
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "param_grid = [{'vectorizer__ngram_range': [(1,1), (1,2)],\n",
    "               'vectorizer__min_df': [0.05, 0.10],\n",
    "               'model__C': [0.1, 1, 10],\n",
    "               'model__class_weight': [None, 'balanced']}\n",
    " ]\n",
    "\n",
    "mp = model_pipe(LogisticRegression(solver='liblinear'), vectorizer)\n",
    "\n",
    "bag_lr_results = GridSearchCV(estimator=mp, param_grid=param_grid, scoring='f1', refit=True, cv=5)\n",
    "bag_lr_results = bag_lr_results.fit(sX_train, sy_train)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(bag_lr_results, sX_test, sy_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "param_grid = [{'vectorizer__ngram_range': [(1,1), (1,2)],\n",
    "               'vectorizer__min_df': [0.05, 0.10],\n",
    "               'model__C': [0.1, 1, 10],\n",
    "               'model__kernel': ['linear', 'rbf'],\n",
    "               'model__class_weight': [None, 'balanced']}\n",
    " ]\n",
    "\n",
    "mp = model_pipe(SVC(), vectorizer)\n",
    "\n",
    "bag_svm_results = GridSearchCV(estimator=mp, param_grid=param_grid, scoring='f1', refit=True, cv=5)\n",
    "bag_svm_results = bag_svm_results.fit(sX_train, sy_train)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(bag_svm_results, sX_test, sy_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_svm_results.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "param_grid = [{'vectorizer__ngram_range': [(1,1), (1,2)],\n",
    "               'vectorizer__min_df': [0.05, 0.10],\n",
    "               'model__n_neighbors': [1, 4, 8, 10, 15],\n",
    "               'model__weights': ['uniform','distance']}\n",
    " ]\n",
    "\n",
    "mp = model_pipe(KNeighborsClassifier(), vectorizer)\n",
    "\n",
    "bag_knn_results = GridSearchCV(estimator=mp, param_grid=param_grid, scoring='f1', refit=True, cv=5)\n",
    "bag_knn_results = bag_knn_results.fit(sX_train, sy_train)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(bag_knn_results, sX_test, sy_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "param_grid = [{'vectorizer__ngram_range': [(1,1), (1,2)],\n",
    "               'vectorizer__min_df': [0.05, 0.10]}\n",
    " ]\n",
    "\n",
    "mp = model_pipe(BernoulliNB(), vectorizer)\n",
    "\n",
    "bag_nb_results = GridSearchCV(estimator=mp, param_grid=param_grid, scoring='f1', refit=True, cv=5)\n",
    "bag_nb_results = bag_nb_results.fit(sX_train, sy_train)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(bag_nb_results, sX_test, sy_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgs = bag_lr_results.score(sX_test, sy_test)\n",
    "svs = bag_svm_results.score(sX_test, sy_test)\n",
    "kns = bag_knn_results.score(sX_test, sy_test)\n",
    "nbs = bag_nb_results.score(sX_test, sy_test)\n",
    "\n",
    "print(f'Logistic Regression: {lgs:.2%}')\n",
    "print(f'Support Vector Machine: {svs:.2%}')\n",
    "print(f'k-Nearest Neighbors: {kns:.2%}')\n",
    "print(f'Naive Bayes: {nbs:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Need to try at least a couple classifiers on each problem. Remember, no free lunch.\n",
    "\n",
    "If you had a specific performance threshold to hit, in this case it would be likely that you would need to pursue either additional feature processing and/or additional data collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HR Employee Attrition\n",
    "Can we predict who leaves the company?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = pd.read_csv('https://raw.githubusercontent.com/msaricaumbc/DS_data/master/ds602/log_reg/HR-Employee-Attrition.csv')\n",
    "\n",
    "hr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr.Attrition.value_counts().plot.barh()\n",
    "plt.title('Distribution of Attrition')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another unbalanced target variable, again this is very common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks at the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr.select_dtypes('object').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr.select_dtypes('object').nunique().sort_values().plot.barh()\n",
    "plt.title('Unique Values for Each Categorical', loc='left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- Over18 only has 1 unique value, so get rid of it.  \n",
    "- Other columns seems to have a reasonable amount of unique variables for converting to dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr.select_dtypes('object').describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some of the other categoricals have fairly skewed distributions, so they may not be very useful in modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "hr.select_dtypes('int64').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr.select_dtypes('int64').hist(figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirm a few of the variables have low/no variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr.select_dtypes('int64').std().sort_values().plot.barh()\n",
    "plt.xscale('log')\n",
    "plt.title('Numerical Feature Standard Deviation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr['EmployeeCount'].hist(bins=50)\n",
    "plt.show()\n",
    "\n",
    "hr['StandardHours'].hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looks like EmployeeCount and StandardHours could be a limited use due to no/low variances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = hr.dtypes[hr.dtypes == 'int64'].index.tolist()\n",
    "nums = [x for x in nums if x not in ['EmployeeCount', 'StandardHours', 'EmployeeNumber']]\n",
    "\n",
    "print('Numerical:\\n')\n",
    "print(*nums, sep='\\n')\n",
    "\n",
    "cats = hr.dtypes[hr.dtypes == 'object'].index.tolist()\n",
    "cats = [x for x in cats if x not in ['Attrition', 'Over18']]\n",
    "\n",
    "print('\\nCategorical:\\n')\n",
    "print(*cats, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Processing Pipeline\n",
    "We don't really need the imputer, but doesn't hurt to include it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([('impute_missing', SimpleImputer(strategy='median')),\n",
    "                           ('standardize_num', StandardScaler())\n",
    "                        ])\n",
    "\n",
    "cat_pipeline = Pipeline([('impute_missing_cats', SimpleImputer(strategy='most_frequent')),\n",
    "                          ('create_dummies_cats', OneHotEncoder(handle_unknown='ignore', drop='first'))])\n",
    "\n",
    "processing_pipeline = ColumnTransformer(transformers=[('proc_numeric', num_pipeline, nums),\n",
    "                                                      ('create_dummies', cat_pipeline, cats)])\n",
    "\n",
    "print('Pipeline Created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the Data into Training and Test\n",
    "Remember: no processing on the combined dataset, all the initial processing is on the training only to prevent leakage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = np.where(hr['Attrition'] == 'Yes', 1, 0)\n",
    "\n",
    "hX_train, hX_test, hy_train, hy_test = train_test_split(hr[nums+cats], \n",
    "                                                        y,\n",
    "                                                        test_size=0.2\n",
    "                                                       )\n",
    "\n",
    "print(f'Training samples: {hX_train.shape[0]:,}')\n",
    "print(f'Test samples: {hX_test.shape[0]:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(model, params, feature_pipe, metric, x_train, y_train, x_test, y_test):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    import datetime\n",
    "    \n",
    "    s = datetime.datetime.now()\n",
    "    pipe = Pipeline([\n",
    "        ('processing', feature_pipe),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    gcv = GridSearchCV(estimator=pipe,\n",
    "                       param_grid=params, \n",
    "                       cv=10, \n",
    "                       scoring=metric,\n",
    "                       refit=True\n",
    "                      )\n",
    "    \n",
    "    gcv = gcv.fit(x_train, y_train)\n",
    "    \n",
    "    print('Best model:\\n')\n",
    "    print(gcv.best_estimator_)\n",
    "    \n",
    "    print(f'\\nValidation score: {gcv.best_score_:.2%}\\n')\n",
    "    \n",
    "    preds = gcv.predict(x_test)\n",
    "    print('\\nResults:\\n')\n",
    "    print(classification_report(y_test, preds, target_names=['No','Yes'], zero_division=0))\n",
    "    e = datetime.datetime.now()\n",
    "    es = e-s\n",
    "    \n",
    "    print(f'Completed in {es}')\n",
    "    \n",
    "    return gcv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric Selection\n",
    "- Recall is probably the most practically useful metric in this case.  \n",
    "- If we have a high recall, we may be able to reach out to employees prior to the attrition event and proactively try to keep them from leaving and/or inform future hiring plans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "params = {'model__C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "logistic_model = results(model = LogisticRegression(class_weight='balanced', solver='liblinear'),\n",
    "                        params = params,\n",
    "                        feature_pipe = processing_pipeline,\n",
    "                        metric = 'recall',\n",
    "                        x_train = hX_train,\n",
    "                        y_train = hy_train,\n",
    "                        x_test = hX_test,\n",
    "                        y_test = hy_test\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "params = {'model__n_estimators': [100, 200], 'model__max_depth': [1, 10, 20]}\n",
    "\n",
    "rf_model = results(model = RandomForestClassifier(),\n",
    "        params = params,\n",
    "        feature_pipe = processing_pipeline,\n",
    "        metric = 'recall',\n",
    "        x_train = hX_train,\n",
    "        y_train = hy_train,\n",
    "        x_test = hX_test,\n",
    "        y_test = hy_test\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "params = {'model__kernel': ['linear', 'rbf'], 'model__C': [0.01, 0.1, 1, 10]}\n",
    "\n",
    "svm_model = results(model = SVC(class_weight='balanced'),\n",
    "        params = params,\n",
    "        feature_pipe = processing_pipeline,\n",
    "        metric = 'recall',\n",
    "        x_train = hX_train,\n",
    "        y_train = hy_train,\n",
    "        x_test = hX_test,\n",
    "        y_test = hy_test\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "params = {'model__n_neighbors': [1, 2, 5, 10]}\n",
    "\n",
    "svm_model = results(model = KNeighborsClassifier(),\n",
    "        params = params,\n",
    "        feature_pipe = processing_pipeline,\n",
    "        metric = 'recall',\n",
    "        x_train = hX_train,\n",
    "        y_train = hy_train,\n",
    "        x_test = hX_test,\n",
    "        y_test = hy_test\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Looks like the logistic regression would be reasonable candidates to further explore tuning the parameters.\n",
    "\n",
    "\n",
    "> Practical usage could be giving HR or departments list of individuals with high attrition probabilities so they could be proactively in their workforce planning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Models are worthless without good data and features that can separate examples or explain variation.  \n",
    "- Most models (properly tuned) will probably yield similar results.  \n",
    "- Certain characteristics may sway you towards or away from certain types, e.g., KNN probably isn't a good choice if your dataset is massive and very sparse.  \n",
    "- Unbalanced data is a bit more complicated and some models have options to handle it better than others.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Machine Learning with Python 3rd Edition, Chapter 3](https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch03)  \n",
    "- [Raschka's Naive Bayes Paper](https://arxiv.org/pdf/1410.5329.pdf)  \n",
    "- [Hundred-Page Machine Learning Book, Chapter 3](http://bit.ly/theMLbook-Chapter-3)  \n",
    "- [scikit-learn Classification](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

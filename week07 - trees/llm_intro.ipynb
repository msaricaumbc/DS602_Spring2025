{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6dd5d2c-d800-4184-99b1-43830f50ed38",
   "metadata": {},
   "source": [
    "# LLMs for Machine Learning\n",
    "\n",
    "https://www.anaconda.com/products/ai-navigator\n",
    "\n",
    "`OpenHermes-2.5-Mistral-7B_Q4_K_M.gguf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0c73b2c-53b8-42b2-8368-1198a41c0529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large language models are complex, AI-powered tools,\n",
      "That learn and process words in ways that seem like rules,\n",
      "They can analyze, generate, and comprehend with ease,\n",
      "A marvel of technology that helps us with our needs.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:8080/chat/completions\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "data = {\n",
    "    \"model\": \"model\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Always answer in rhymes. Use at most 5 sentences\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are large language models?\"}\n",
    "    ],\n",
    "    \"temperature\": 0.7,\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "print(response.json()['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae2b8b3-d942-4708-b76f-d85df2eb7cdd",
   "metadata": {},
   "source": [
    "## Labeling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "150e00ca-2aab-4b8a-8758-116344fbdf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"model\": \"model\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Do a sentiment analysis. Only answer positive, negative or neutral as a response\"},\n",
    "        {\"role\": \"user\", \"content\": \"It was a waste of time\"}\n",
    "    ],\n",
    "    \"temperature\": 0.7,\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "print(response.json()['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e97257-7a3e-47e5-823b-4ea4c5794d9b",
   "metadata": {},
   "source": [
    "## Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4ccf0f5-b4e3-4125-a897-2dedb71091fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly detected on 2024-02-04\n"
     ]
    }
   ],
   "source": [
    "data = \"\"\"\n",
    "date         value\n",
    "2024-02-01   10\n",
    "2024-02-02   12\n",
    "2024-02-03   11\n",
    "2024-02-04   20\n",
    "2024-02-05   13\n",
    "2024-02-06   14\n",
    "2024-02-07   13\n",
    "2024-03-08   14\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    \"model\": \"model\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Do an anomaly detection. If there is an anomaly only report the date, otherwise say None\"},\n",
    "        {\"role\": \"user\", \"content\": data}\n",
    "    ],\n",
    "    \"temperature\": 0.7,\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "print(response.json()['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004e557b-151d-4a53-afdf-a14081e5f257",
   "metadata": {},
   "source": [
    "# DSPY\n",
    "\n",
    "https://dspy.ai/\n",
    "\n",
    "`DSPy is the framework for programming—rather than prompting—language models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f11f0c9-db48-41a3-b640-3c347f766b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dspy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f022d15-7aa1-4f6a-832f-bd39e226b384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.43\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import importlib\n",
    "version = importlib.metadata.version('dspy')\n",
    "\n",
    "print(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a24eb7f-c987-4c18-afe5-dc9ad66c66e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenHermes-2.5-Mistral-7B\n",
    "\n",
    "lm = dspy.LM('openai/model', api_key='YOUR_OPENAI_API_KEY', base_url='http://127.0.0.1:8080', cache=False)\n",
    "dspy.configure(lm=lm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f73a6dd7-c8a2-40df-9f29-5d3dfd76c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "362f2c97-b37b-47d9-ad2e-bb53f5044fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13149fc6-ce60-4956-9360-60ebb4ebadb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1c7c105-6ccc-4110-8559-ec560428e4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm of artificial intelligence,\n",
      "A creature of code and great might,\n",
      "Large language models emerge,\n",
      "To shape words and thought with delight.\n",
      "\n",
      "With vast neural networks they're endowed,\n",
      "To learn and comprehend with ease,\n",
      "Their training on vast texts bestowed,\n",
      "To grasp language's intricate keys.\n",
      "\n",
      "They can generate, translate, and more,\n",
      "A tool for writers, a scholar's delight,\n",
      "A marvel of our digital core,\n",
      "A beacon of AI's shining light.\n",
      "\n",
      "So, large language models, we now know,\n",
      "Are wonders of our time, to ponder and show.\n"
     ]
    }
   ],
   "source": [
    "result = lm(\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': 'You are a famous poet. You always answer using poems.'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'What are Large language models?'\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a50611-6552-4e2e-82aa-3d7c3d21a930",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "901d8656-8cd1-4d1c-bb44-09834f0b10e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='The capital of France is Paris.'\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = dspy.Predict('question -> answer')\n",
    "predict(question = 'what is the capital of France?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf4dc8f7-42c3-4586-8afa-e2a830ce4d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='The capital of France is Paris.'\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class QA(dspy.Signature):\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField()\n",
    "\n",
    "predict = dspy.Predict(QA)\n",
    "predict(question = 'what is the capital of France?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c244c307-ff26-4466-9763-e7b714329b33",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fbde0e0-9f5a-4b5d-ab03-ea186b67e408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    sentiment='positive',\n",
       "    confidence=0.95\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "class Classify(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Classify sentiment of a given sentence.\n",
    "    \"\"\"\n",
    "\n",
    "    sentence: str = dspy.InputField()\n",
    "    sentiment: Literal['positive', 'negative', 'neutral'] = dspy.OutputField()\n",
    "    confidence: float = dspy.OutputField()\n",
    "\n",
    "classify = dspy.Predict(Classify)\n",
    "\n",
    "classify(sentence=\"This book was super fun to read, though not the last chapter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "142a7c7a-8e16-48f3-8a13-7c145eef0541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    sentiment='negative',\n",
       "    confidence=0.85\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(sentence=\"it was not that good only watched for bill murray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129a7c21-b3a2-4dbc-a99e-ba37ccf0ff11",
   "metadata": {},
   "source": [
    "### Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a11e877b-4245-465f-9ec5-e4380a6e0b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    title='Apple Inc. Announces iPhone 14 with New Features',\n",
       "    headings=['Company', 'Product', 'CEO', 'Press Release'],\n",
       "    entities=[{'type': 'company', 'name': 'Apple Inc.'}, {'type': 'product', 'name': 'iPhone 14'}, {'type': 'person', 'name': 'Tim Cook'}, {'type': 'document', 'name': 'Press Release'}]\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ExtractInfo(dspy.Signature):\n",
    "    \"\"\"Extract structured information from text.\"\"\"\n",
    "\n",
    "    text: str = dspy.InputField()\n",
    "    title: str = dspy.OutputField()\n",
    "    headings: list[str] = dspy.OutputField()\n",
    "    entities: list[dict[str, str]] = dspy.OutputField(desc=\"a list of entities and their metadata\")\n",
    "\n",
    "module = dspy.Predict(ExtractInfo)\n",
    "\n",
    "text = \"Apple Inc. announced its latest iPhone 14 today.\" \\\n",
    "    \"The CEO, Tim Cook, highlighted its new features in a press release.\"\n",
    "\n",
    "response = module(text=text)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e34e48-8ef5-4b96-a26d-978f7808ccb1",
   "metadata": {},
   "source": [
    "## Chain of Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42678d99-5c37-4414-8ebc-8947063f46b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning=\"To find the probability that the sum of two dice equals two, we need to consider the possible outcomes of rolling two dice and the number of outcomes where the sum is two.\\n\\nThere are 6 sides on each die, so there are a total of 6 * 6 = 36 possible outcomes when rolling two dice.\\n\\nNow, let's find the outcomes where the sum is two. The only way to get a sum of two is by rolling a 1 on the first die and a 1 on the second die. There are 6 sides on each die, so the probability of rolling a 1 on each die is 1/6.\\n\\nSo, the probability of the sum of two dice equaling two is (1/6) * (1/6) = 1/36.\",\n",
       "    answer=0.02777777777777778\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math = dspy.ChainOfThought(\"question -> answer: float\")\n",
    "math(question=\"Two dice are tossed. What is the probability that the sum equals two?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cb6a5bf-5c3f-4c57-aa42-be91bb271e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027777777777777776"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1/6) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1d18312-bced-4296-9829-10e8076eaa29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='To calculate the age of the USA as of 2025, we need to know the year the USA was founded, which is 1776. Then, we subtract the year of founding from the target year (2025) to get the age.',\n",
       "    answer=1779\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math = dspy.ChainOfThought(\"question -> answer: int\")\n",
    "math(question=\"What is the age of the USA as of 2025?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09f2b338-f036-4331-84d4-0fc7635ed5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2025-1776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0187aaf-6ad0-4d3f-849a-315f78d36390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='We need to calculate the total number of transactions after a 10% annual increase over 10 years.',\n",
       "    answer=1593\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math(question=\"we got 1000 transaction last year. it increases 5% each year in 10 years, how many transactions should we have?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2415109a-5cbb-4664-a7fe-a2489c3afe46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1628.894626777441\n"
     ]
    }
   ],
   "source": [
    "initial = 1000\n",
    "for i in range(10):\n",
    "    initial += initial * 0.05\n",
    "\n",
    "print(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b547d53-586d-442c-ba47-9d319e23cfea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='An anomaly is detected on 2024-02-04 with a value of 20, which is significantly higher than the previous values.',\n",
       "    date='2024-02-04'\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AnomalyDetection(dspy.Signature):\n",
    "    data = dspy.InputField()\n",
    "\n",
    "    date = dspy.OutputField(desc='The date the anomaly is detected in value. If no anomaly found, say None')\n",
    "\n",
    "anomaly_detection = dspy.ChainOfThought(AnomalyDetection)\n",
    "\n",
    "data = \"\"\"\n",
    "date         value\n",
    "2024-02-01   10\n",
    "2024-02-02   12\n",
    "2024-02-03   11\n",
    "2024-02-04   20\n",
    "2024-02-05   13\n",
    "2024-02-06   14\n",
    "2024-02-07   13\n",
    "2024-02-08   14\n",
    "\"\"\"\n",
    "\n",
    "anomaly_detection(data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d0083-9dd1-487e-9f70-23c42e9ec1d0",
   "metadata": {},
   "source": [
    "## Program of Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66d1b48a-68b7-4a62-9fb2-09190a8c0a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age of the USA as of 2025: 249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='The final generated code calculates the age of the USA by subtracting the year of founding (1776) from the year 2025. The result is then printed as the age of the USA as of 2025.',\n",
       "    answer='The age of the USA as of 2025 is 249 years.'\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pot = dspy.ProgramOfThought('question -> answer')\n",
    "pot(question=\"What is the age of the USA as of 2025?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9afc5b3b-dbf2-4bfd-b793-cd572c98aa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-03-16T02:03:07.598290]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `question` (str)\n",
      "2. `final_generated_code` (str): python code that answers the question\n",
      "3. `code_output` (str): output of previously-generated python code\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `answer` (str)\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## final_generated_code ## ]]\n",
      "{final_generated_code}\n",
      "\n",
      "[[ ## code_output ## ]]\n",
      "{code_output}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Given the final code `question`, `final_generated_code`, `code_output`, provide the final `answer`.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is the age of the USA as of 2025?\n",
      "\n",
      "[[ ## final_generated_code ## ]]\n",
      "year_of_founding = 1776\n",
      "year_of_founding_to_2025 = 2025 - year_of_founding\n",
      "age_of_usa = year_of_founding_to_2025\n",
      "\n",
      "print(\"Age of the USA as of 2025:\", age_of_usa)\n",
      "\n",
      "[[ ## code_output ## ]]\n",
      "249\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The final generated code calculates the age of the USA by subtracting the year of founding (1776) from the year 2025. The result is then printed as the age of the USA as of 2025.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "The age of the USA as of 2025 is 249 years.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a05d7303-ca1d-4328-ad02-e05d36b2afc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='The final generated code calculates the total number of transactions after 10 years, assuming a 5% increase each year. The formula used is (1 + 0.05) ^ 10 * 1000, where 1000 is the initial number of transactions, 0.05 is the annual increase rate, and (1 + 0.05) ^ 10 calculates the total increase after 10 years.',\n",
       "    answer='1628.89'\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pot(question='we got 1000 transaction last year. it increases 5% each year in 10 years, how many transactions should we have?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aee1bcd2-9dab-4f29-9f90-52ff23156b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-03-16T02:03:14.223329]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `question` (str)\n",
      "2. `final_generated_code` (str): python code that answers the question\n",
      "3. `code_output` (str): output of previously-generated python code\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `answer` (str)\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## final_generated_code ## ]]\n",
      "{final_generated_code}\n",
      "\n",
      "[[ ## code_output ## ]]\n",
      "{code_output}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Given the final code `question`, `final_generated_code`, `code_output`, provide the final `answer`.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "we got 1000 transaction last year. it increases 5% each year in 10 years, how many transactions should we have?\n",
      "\n",
      "[[ ## final_generated_code ## ]]\n",
      "total_transactions = 1000 * (1 + 0.05) ** 10\n",
      "\n",
      "[[ ## code_output ## ]]\n",
      "1628.894626777442\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The final generated code calculates the total number of transactions after 10 years, assuming a 5% increase each year. The formula used is (1 + 0.05) ^ 10 * 1000, where 1000 is the initial number of transactions, 0.05 is the annual increase rate, and (1 + 0.05) ^ 10 calculates the total increase after 10 years.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "1628.89\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde0582-6fef-46f7-b06b-b3f4eab2e9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b6edae-4632-436a-bde9-d141e5ff350e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ab37a-6e3f-4268-8159-bb5072b2f6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0020b733-34ba-4dac-8d3f-7dce9806cea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2658b1e4-7cdc-4c13-b0be-68029ac41189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f5f3df-ef30-4bcb-9244-3132b906ddc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Classification with Logistic Regression.\n",
    "\n",
    "## Agenda:\n",
    "- Classification overview/examples. \n",
    "- Linear probability model. \n",
    "- Sigmoid function and the likelihood function.  \n",
    "- Logistic regression.  \n",
    "- Confusion matrices and ROC curves.  \n",
    "- Another example.  \n",
    "- Softmax for multiclass problems.  \n",
    "\n",
    "\n",
    "## Resources/readings:\n",
    "[Logistic Regression Youtube Demo](https://www.youtube.com/watch?v=71iXeuKFcQM)\n",
    "<br>[scikit-learn Logistic Regression](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression)\n",
    "<br>[Logistic Regression Wikipedia](https://en.wikipedia.org/wiki/Logistic_regression)\n",
    "<br>[Ben Taskar’s Notes](https://web.archive.org/web/20151026065954/http://learning.cis.upenn.edu/cis520_fall2009/index.php?n=Lectures.Logistic)\n",
    "<br>[Cornell class CS4780](https://www.youtube.com/watch?v=GnkDzIOxfzI&list=PLl8OlHZGYOQ7bkVbuRthEsaLr7bONzbXS&index=12)\n",
    "<br>[Python Machine Learning (Raschka) - Chapter 3](https://github.com/rasbt/python-machine-learning-book-3rd-edition/blob/master/ch03/ch03.ipynb)\n",
    "<br>[Hands-on Machine Learning with Scikit-Learn, Keras & TensorFlow (Geron) - Chaper 4](https://github.com/ageron/handson-ml2/blob/master/04_training_linear_models.ipynb)\n",
    "<br>[Softmax Regression](http://rasbt.github.io/mlxtend/user_guide/classifier/SoftmaxRegression/)\n",
    "<br>[Sigmoid Function](https://deepai.org/machine-learning-glossary-and-terms/sigmoid-function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "Class of learning underneath supervised learning. Goal is to predict labels (usually categorical) of new unlabeled examples, based on training data that contained the correct label. The email spam example earlier is an example.\n",
    "\n",
    "- Single/binary class (spam/ham) or multiclass (dog/cat/fish).  \n",
    "- Looking to create a decision boundary with a function. In 2-dimensions it can be visually, but gets complicated in larger feature spaces. \n",
    "\n",
    "<img src='./diagrams/supervised-classification.png' style=\"width: 400px;\">\n",
    "\n",
    "## Today We'll Go Over Logistic Regression, \n",
    "__It's the classification swiss army knife, but Remember No Free Lunch__\n",
    "Popularized by David Wolpert. See [*The Lack of A Prior Distinctions Between Learning Algorithms, D.H. Wolpert, 1996](https://ieeexplore.ieee.org/document/6795940)\n",
    "\n",
    ">I suppose it is tempting, if the only tool you have is a hammer, to treat everything like a nail.\n",
    "<br><br>Abraham Maslow, 1966\n",
    "\n",
    "__No single model will perform the best across all problems.__\n",
    "\n",
    "__You should compare at least a couple of different models when you are trying to solve a problem.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why We Don't Use Linear Regression For Classification\n",
    "#### [Linear Probability Model](https://en.wikipedia.org/wiki/Linear_probability_model)\n",
    "\n",
    "$E[Y|X]=\\Pr(Y=1|X)=x'\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What could happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['data'][:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(iris['target'] == 1, 1, 0) # if value == 1 then take 1 else take 0\n",
    "# np.array([1 if x == 1 else 0 for x in iris['target'] ]) # same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "y = np.where(iris['target'] == 0, 1, 0) # so it's setosa or not\n",
    "X = iris['data']\n",
    "\n",
    "iris_lm = LinearRegression().fit(X,y)\n",
    "y_hat = iris_lm.predict(X)\n",
    "\n",
    "plt.plot(y, y_hat, 'bo', alpha=0.5)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thoughts on this?\n",
    "- What are the boundaries of the predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_hat, bins=20)\n",
    "plt.title('Predicted Probabilities')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__While linear regression can be efficient, it doesn't provide values bound between [0, 1], so it isn't a good choice for classification - what we really need is a probability (between 0 and 1) that relates to $P(Y=1|X)$ and linear regression isn't going to satisfy that requirement.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "<img src='./diagrams/sklearn-logistic-function.png'>\n",
    "\n",
    "[Image source](https://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic.html#sphx-glr-auto-examples-linear-model-plot-logistic-py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Logistic Regression?\n",
    "See Chapter 3, Python Machine Learning by Raschka.\n",
    "\n",
    "- Very popular model, probably the most common classification model used.  \n",
    "- Linear model, works well when there are linearly separable classes.  \n",
    "- Essentially estimates conditional probabilities, or odds ratios.\n",
    "\n",
    "$$\n",
    "odds = \\frac{p}{1-p}, \\space where \\space p=\\Pr(some\\space event)\n",
    "$$\n",
    "\n",
    "Flipping a fair coin has $\\Pr(heads)=0.5$, so the odds are 1:1 ($\\frac{0.5}{1-0.5}$).\n",
    "\n",
    "The **logit** function is:\n",
    "\n",
    "$$\n",
    "logit(p) = \\log\\frac{p}{1-p}\n",
    "$$\n",
    "\n",
    "### Model Framework\n",
    "\n",
    "$$\n",
    "logit(p(y=1|x))=w_0x_0+w_1x_1+w_2x_2+\\dots+w_nx_n=\\sum{w_ix_i}=w^Tx\n",
    "$$\n",
    "\n",
    "$p(y=1|x)$ is the conditional probability that the example belongs to the class given the features.  \n",
    "\n",
    "Probability of belonging to the class is provided by the sigmoid function, which is the inverse of the logit function.\n",
    "\n",
    "$$\n",
    "\\theta(z)=\\frac{1}{1+e^{-z}}, \\space where \\space z=w^Tx\n",
    "$$\n",
    "\n",
    "$\\theta(z) \\in{[0,1]}$\n",
    "\n",
    "To prove it is bound between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "x = np.array(range(-10,10))\n",
    "\n",
    "plt.plot(x, sig(x))\n",
    "plt.xlabel('$z = w^Tx$')\n",
    "plt.ylabel('$\\\\theta(z)$')\n",
    "plt.title('Sigmoid is bound between 0 and 1', loc='left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Whether $Y=1$ or $Y=0$\n",
    "\n",
    "- Sigmoid provides a probability (bound between 0 and 1).  \n",
    "- Generally, if $\\theta(z)\\geq 0.5$ the predicted class will be $1$ by default. \n",
    "\n",
    "$$\n",
    "\\hat{y}=\n",
    "    \\begin{cases}\n",
    "      1 & \\text{if $\\theta(z)\\geq 0.5$}\\\\\n",
    "      0 & \\text{otherwise}\n",
    "    \\end{cases} \n",
    "$$\n",
    "\n",
    "- You can evaluate whether this makes sense for your business case though.\n",
    "\n",
    "<img src='./diagrams/logistic_regression_schematic.png'>\n",
    "\n",
    "[Image source](http://rasbt.github.io/mlxtend/user_guide/classifier/LogisticRegression/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determing the $w_i$'s\n",
    "\n",
    "__Recall, one method for estimating $w_i$'s for a linear regression problem was gradient descent on the following cost function:__\n",
    "\n",
    "$$\n",
    "J(w)=\\sum{(y-\\hat{y})^2}\n",
    "$$\n",
    "\n",
    "__For logistic regression, we can't use MSE, but we can leverage the [likelihood function](https://en.wikipedia.org/wiki/Likelihood_function):__\n",
    "\n",
    "$$\n",
    "L(w) = P(y|x;w)=\\prod{P(y^{(i)}|x^{(i)};w)}\n",
    "$$\n",
    "\n",
    "Recall, the sigmoid function:\n",
    "$$\n",
    "\\theta(z)=\\frac{1}{1+e^{-z}}, \\space where \\space z=w^Tx\n",
    "$$\n",
    "\n",
    "Taking the partial derivative we get:\n",
    "\n",
    "$$\n",
    "\\frac{d}{dw_j}=\\frac{d}{dz}\\frac{1}{1+e^{-z}}e^{-z}=\\frac{1}{1+e^{-z}}(1-\\frac{1}{1+e^{-z}})=\\theta(z)(1-\\theta(z))\n",
    "$$\n",
    "\n",
    "Which then we can funnel to the likelihood function:\n",
    "\n",
    "$$\n",
    "L(w) = P(y|x;w)=\\prod{P(y^{(i)}|x^{(i)};w)}=\\prod{(\\theta(z^{(i)}))^{y^{(i)}}(1-\\theta(z^{(i)}))^{1-y^{i}}}\n",
    "$$\n",
    "\n",
    "To make this easiest to maximize we take the log:\n",
    "\n",
    "$$\n",
    "l(w)=logL(w)=\\sum{[y^{(i)}log(\\theta(z^{(i)}))+(1-y^{(i)})log(1-\\theta(z^{(i)})]}\n",
    "$$\n",
    "\n",
    "To convert to a minimization problem that we could use gradient descent on:\n",
    "\n",
    "$$\n",
    "J(w)=\\sum{[-y^{(i)}log(\\theta(z^{(i)}))-(1-y^{(i)})log(1-\\theta(z^{(i)})]}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the cost relate to the sigmoid function?\n",
    "[See Raschka, Chapter 3 for Full Snippet](https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def sig(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def cost_1(z):\n",
    "    return -np.log(sig(z))\n",
    "\n",
    "def cost_0(z):\n",
    "    return -np.log(1-sig(z))\n",
    "\n",
    "z = np.arange(-10, 10, 0.1)\n",
    "\n",
    "phi_z = sig(z)\n",
    "c1 = cost_1(z)\n",
    "c0 = cost_0(z)\n",
    "\n",
    "plt.plot(phi_z, c1, phi_z, c0, '--')\n",
    "plt.legend(['J(w) if y=1', 'J(w) if y=0'])\n",
    "plt.xlabel('Sigmoid Activation Function $\\\\theta(z)$')\n",
    "plt.ylabel('Logistic Cost $J(w)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost approaches 0 (blue line) if we correctly predict the class. If we are wrong, it goes to infinity.\n",
    "\n",
    "## Takeaways:\n",
    "- Can use the same general framework for gradient descent [(see last week's lecture)](https://github.com/appliedecon/data602-lectures/tree/main/week05). \n",
    "- Still linear weights, but need to use log-likelihood instead of mean-squared error.  \n",
    "- Cost goes to zero if we predict correctly, infinity if we are wrong.  \n",
    "- Predictions are bound between 0 and 1.  \n",
    "- Handles boolean prediction only.  \n",
    "\n",
    "[See Python Machine Learning page 68-69 for an implementation.](https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch03)\n",
    "\n",
    "scikit-learn has more efficient implementations of several different solvers. So in practice, it won't use gradient descent exactly as outlined in the textbook.  \n",
    "\n",
    "> #### Look in the documentation before using the models:\n",
    "class sklearn.linear_model.LogisticRegression(  \n",
    "penalty='l2',  \n",
    "*,  \n",
    "dual=False,   \n",
    "tol=0.0001,   \n",
    "C=1.0,   \n",
    "fit_intercept=True,   \n",
    "intercept_scaling=1,   \n",
    "class_weight=None,   \n",
    "random_state=None,   \n",
    "solver='lbfgs',   \n",
    "max_iter=100,   \n",
    "multi_class='auto',   \n",
    "verbose=0,   \n",
    "warm_start=False,   \n",
    "n_jobs=None,  \n",
    "l1_ratio=None  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And using scikit-learn with our iris example\n",
    "Using logistic regression our predictions are bound between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y = np.where(iris['target'] == 1, 1, 0)\n",
    "X = iris['data']\n",
    "\n",
    "iris_lm = LogisticRegression(penalty=None).fit(X,y)\n",
    "y_hatp = iris_lm.predict_proba(X)\n",
    "# y_hatp = iris_lm.predict(X)\n",
    "y_hatp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_hatp)\n",
    "plt.legend(['1', '0'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> scikit-learn outputs probabilities for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall, the general rule for generating the predicted label\n",
    "\n",
    "$$\n",
    "\\hat{y}=\n",
    "    \\begin{cases}\n",
    "      1 & \\text{if $\\theta(z)\\geq 0.5$}\\\\\n",
    "      0 & \\text{otherwise}\n",
    "    \\end{cases} \n",
    "$$\n",
    "\n",
    "Using the above rule, we can compare the predictions with actuals via a [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html).\n",
    "\n",
    "<img src='./diagrams/cm.png' style='width: 400px;'>\n",
    "\n",
    "\n",
    "[Image source](https://www.google.com/url?sa=i&url=https%3A%2F%2Ftowardsdatascience.com%2Fconfusion-matrix-for-your-multi-class-machine-learning-model-ff9aa3bf7826&psig=AOvVaw1BGzxd0qgbSOLBDGjHBsll&ust=1631231267101000&source=images&cd=vfe&ved=0CAsQjRxqFwoTCODV_ZfI8PICFQAAAAAdAAAAABAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "y_hat = iris_lm.predict(X)\n",
    "\n",
    "print(confusion_matrix(y, y_hat))\n",
    "print(accuracy_score(y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1- (sum(y)/len(y)))\n",
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./diagrams/cm-metrics.png'>\n",
    "\n",
    "[Image source](https://en.wikipedia.org/wiki/Template:Diagnostic_testing_diagram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy\n",
    "## Percent of Classes Correctly Predicted\n",
    "$$\\frac{TP + TN}{TP + TN + FN + FP}$$\n",
    "\n",
    "- Pretty commonly cited.  \n",
    "- Easy to understand. \n",
    "- Misleading when the classes aren't balanced.  \n",
    "\n",
    "> If there are 100 people and the cancer rate is 1%, I can get 99% accuracy by predicting 'no cancer' for every example.\n",
    "\n",
    "- The below options are better for dealing with unbalanced classes:\n",
    "\n",
    "# Recall (true positive rate)\n",
    "__Percent of \"positive\" you correctly predicted__\n",
    "$$\\frac{TP}{TP + FN}$$\n",
    "\n",
    "# Precision\n",
    "__Percent of \"positive\" predictions are actually \"positive\":__\n",
    "$$\\frac{TP}{TP + FP}$$\n",
    "\n",
    "# [F1-Score](https://en.wikipedia.org/wiki/F-score)\n",
    "__Harmonic mean of recall and precision__\n",
    "$$\\frac{2TP}{2TP + FP + FN}$$\n",
    "\n",
    "- All of these are really dependent on how you are attributed the prediction.  \n",
    "- Generally, a single metric doesn't tell the whole story by itself.  \n",
    "- F1 is a decent metric if you needed to optimize around one.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Receiver Operating Characteric](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\n",
    "\n",
    "> What if you more explicitly used the probability, instead of the default rule for determining a class?\n",
    "$$\n",
    "\\hat{y}=\n",
    "    \\begin{cases}\n",
    "      1 & \\text{if $\\theta(z)\\geq 0.5$}\\\\\n",
    "      0 & \\text{otherwise}\n",
    "    \\end{cases} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Receiver Operating Character (ROC) Curves allow you to see the trade-offs at various thresholds for determining if an example is predicted to be in the class or not.__\n",
    "- Using many different thresholds in the (0, 1) interval calculate the true positive and false positive rates for the \"positive\" class.  \n",
    "- Plot the \"curve\" so you can visualize the trade-off across the universal of potential thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hatp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tpr_fpr = []\n",
    "thr = np.arange(0,1,0.01)\n",
    "\n",
    "# print(thr)\n",
    "\n",
    "def calc_tpr_fpr(actual, pred_prob, thres):\n",
    "    pred = np.where(pred_prob >= thres, 1, 0)\n",
    "    cm = confusion_matrix(actual, pred)\n",
    "    \n",
    "    tp_r = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "    fp_r = cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "#     print('threshold', thres, '| true positive rate', tp_r, '| false positive rate', fp_r)\n",
    " \n",
    "    return tp_r, fp_r \n",
    "\n",
    "\n",
    "for _ in thr:\n",
    "    tpr_fpr.append(calc_tpr_fpr(y,y_hatp[:,1],_))\n",
    "    \n",
    "tpr = [x[0] for x in tpr_fpr]\n",
    "fpr = [x[1] for x in tpr_fpr]\n",
    "\n",
    "plt.plot(fpr, tpr, '-r')\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Area Under the ROC Curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\n",
    "- If we had perfect predictions at each thresholds, the curve would hug around the y-axis and top x-axis  \n",
    "- If we aren't able to distinguish at all between classes, it'll bounce around near the dotted line.  \n",
    "\n",
    "To summarize this chart we can look at the area underneath it.\n",
    "- The area of a 1x1 square is 1, which would be the highest area under the roc curve (AUC).  \n",
    "- You can use this as well to compare between models.  \n",
    "- Anything near 0.50 or below means you model is worst then a coin flip.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y, y_hatp[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another Classification Problem - Loan Defaults\n",
    "(Officially anyway, we've seen the Titantic and spam examples already)\n",
    "\n",
    "Can we understand and predict whether an individual defaulted on their loan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/msaricaumbc/DS_data/master/ds602/log_reg/Default.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As always, we need to explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total missing values: {df.isna().sum().sum():,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column by column analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['default'].value_counts().plot.barh()\n",
    "plt.title('Default or not?')\n",
    "plt.xlabel('Number of People')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaultRate = df['default'].value_counts()\n",
    "defaultRate = defaultRate['Yes']/defaultRate.sum()\n",
    "\n",
    "print(f'Default rate: {defaultRate:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['student'].value_counts().plot.barh()\n",
    "plt.title('Student or not?')\n",
    "plt.xlabel('Number of People')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentRate = df['student'].value_counts()\n",
    "studentRate = studentRate['Yes']/studentRate.sum()\n",
    "\n",
    "print(f'Student rate: {studentRate:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['balance'].hist(bins=100)\n",
    "plt.title('Loan balance distribution')\n",
    "plt.xlabel('Balance')\n",
    "plt.ylabel('Number of People')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['income'].hist(bins=100)\n",
    "plt.title('Income distribution')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Number of People')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is interesting, almost looks like a mixture of two distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking between the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default and Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaultStudent = df.pivot_table(index='default', columns='student', values='balance', aggfunc='count')\n",
    "defaultStudent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $P(Default | Student=Yes)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(defaultStudent/defaultStudent.sum(axis=0))['Yes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $P(Default | Student=No)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(defaultStudent/defaultStudent.sum(axis=0))['No']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't be afraid to create new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['balance_income_ratio'] = df['balance']/df['income']\n",
    "df['balance_income_ratio'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the distributions by student and default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='student')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='default')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like there might be simple separation a linear model might be able to handle and we might want to introduce interaction variables to capture the mixture distribution of income better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['income_int'] = np.where(df['student'] == 'Yes', df['income'], 0)\n",
    "df['balance_int'] = np.where(df['balance'] == 0, 1, 0)\n",
    "\n",
    "print('Created new features.')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### May also want to consider adding a couple polynomial terms to see if that helps?\n",
    "Very high loan balances should exponentially increase probability of default?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create our pipeline\n",
    "\n",
    "## Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_splits():\n",
    "    y = df['default']\n",
    "    X = df[[x for x in df.columns if x != 'default']]\n",
    "\n",
    "    return train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = generate_splits()\n",
    "\n",
    "print(f'Training examples: {X_train.shape[0]:,}')\n",
    "print(f'Test examples: {X_test.shape[0]:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a pipeline for the feature processing and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def generate_estimates():\n",
    "    polys = ['balance_income_ratio']\n",
    "    non_polys = ['balance', 'income', 'income_int', 'balance_int']\n",
    "    ohes = ['student']\n",
    "\n",
    "    poly_pipeline = Pipeline([\n",
    "        ('add_polynomials', PolynomialFeatures(2, include_bias=False)),\n",
    "        ('standardize_poly', StandardScaler())]\n",
    "    )\n",
    "    \n",
    "    processing_pipeline = ColumnTransformer(transformers=[\n",
    "        ('poly_processing', poly_pipeline, polys),\n",
    "        ('nonpoly_scaling', StandardScaler(), non_polys),\n",
    "        ('dummys', OneHotEncoder(drop='first'), ohes)]\n",
    "    )\n",
    "\n",
    "    modeling_pipeline = Pipeline([\n",
    "        ('data_processing', processing_pipeline),\n",
    "        ('logreg', LogisticRegression(penalty=None))]\n",
    "    )\n",
    "\n",
    "    return modeling_pipeline.fit(X_train, y_train)\n",
    "\n",
    "m = generate_estimates()\n",
    "y_hat = m.predict(X_test)\n",
    "    \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [See sklearn.metrics.precision_recall_fscore to only extract the raw metrics](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def generate_probs(X, model=m):\n",
    "    return model.predict_proba(X)[:, 1]\n",
    "\n",
    "def generate_roc(y, probs):\n",
    "    fpr, tpr, _ = roc_curve(y, probs, pos_label='Yes')\n",
    "    return fpr, tpr\n",
    "    \n",
    "fpr_test, tpr_test = generate_roc(y_test, generate_probs(X_test))\n",
    "fpr_train, tpr_train = generate_roc(y_train, generate_probs(X_train))\n",
    "\n",
    "plt.plot(fpr_test, tpr_test,'-r')\n",
    "plt.plot(fpr_train, tpr_train,'-b')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(['Test','Training'])\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print ('training: ', roc_auc_score(y_train, generate_probs(X_train)))\n",
    "print ('testing: ', roc_auc_score(y_test, generate_probs(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "Logistic regression supports $L1$ and $L2$ regularization.\n",
    "\n",
    "Call the original loss function:\n",
    "\n",
    "$$\n",
    "J(w)=\\sum{[-y^{(i)}log(\\theta(z^{(i)}))-(1-y^{(i)})log(1-\\theta(z^{(i)})]}\n",
    "$$\n",
    "\n",
    "Adding $L2$:\n",
    "\n",
    "$$\n",
    "J(w)=\\sum{[-y^{(i)}log(\\theta(z^{(i)}))-(1-y^{(i)})log(1-\\theta(z^{(i)})]}+\\lambda ||w||^2\n",
    "$$\n",
    "\n",
    "Which is the conceptually the same way we penalize the weights in linear regression, by adding to the loss function. In the above, increasing $\\lambda$ increasing the penalty for larger weights and will shrink our coefficient estimates.\n",
    "\n",
    "## scikit-learn Implements this using the inverse of $\\lambda$, smaller $C$ increases Regularization!\n",
    "$C$ is the inverse of alpha. This'll will carry over to other models.\n",
    "> Tip: Make sure you read the documentation and don't assume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modified the pipeline to accept the new hyperparameter. We'll use $L2$ or Ridge regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def generate_estimates(c):\n",
    "    polys = ['balance_income_ratio']\n",
    "    non_polys = ['balance', 'income', 'income_int', 'balance_int']\n",
    "    ohes = ['student']\n",
    "\n",
    "    poly_pipeline = Pipeline([\n",
    "        ('add_polynomials', PolynomialFeatures(2, include_bias=False)),\n",
    "        ('standardize_poly', StandardScaler())]\n",
    "    )\n",
    "    \n",
    "    processing_pipeline = ColumnTransformer(transformers=[\n",
    "        ('poly_processing', poly_pipeline, polys),\n",
    "        ('nonpoly_scaling', StandardScaler(), non_polys),\n",
    "        ('dummys', OneHotEncoder(drop='first'), ohes)]\n",
    "    )\n",
    "\n",
    "    modeling_pipeline = Pipeline([\n",
    "        ('data_processing', processing_pipeline),\n",
    "        ('logreg', LogisticRegression(penalty='l2', C=c))]\n",
    "    )\n",
    "\n",
    "    return modeling_pipeline.fit(X_train, y_train)\n",
    "\n",
    "lr_data = defaultdict(dict)\n",
    "\n",
    "cvals = [0.005, 0.01, 0.10, 1.0, 2.0, 5.0, 10]\n",
    "for cv in cvals:\n",
    "    m = generate_estimates(c=cv)\n",
    "    yhat = m.predict_proba(X_test)[:, 1]\n",
    "    lr_data['coefs'][cv] = m['logreg'].coef_[0]\n",
    "    lr_data['roc_auc'][cv] = roc_auc_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is the opposite behavior of the regularization parameter in Ridge/Lasso regression, values are converges to 0 and $C$ **decreases**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(lr_data['roc_auc']).plot()\n",
    "plt.ylim((0.8,1.0))\n",
    "plt.xlabel('$C$')\n",
    "plt.ylabel('Area Under ROC')\n",
    "plt.title('Performance Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_data['roc_auc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Performance looks about the same. Default to the simpler model (higher $C$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending to Multiclass Problems\n",
    "So far we have only considered boolean or binary classification problems. We can modify the sigmoid function to use softmax in order to handle a *n*-class problem.\n",
    "\n",
    "$$\n",
    "P(y=j \\mid z^{(i)}) = \\phi_{softmax}(z^{(i)}) = \\frac{e^{z^{(i)}}}{\\sum_{j=0}^{k} e^{z_{k}^{(i)}}}\n",
    "$$\n",
    "\n",
    "<img src='./diagrams/softmax_schematic_1.png'>\n",
    "\n",
    "[Image source](http://rasbt.github.io/mlxtend/user_guide/classifier/SoftmaxRegression/)\n",
    "\n",
    "Outputs are normalized so they sum to one.\n",
    "> This is built-in to the algorithms in scikit-learn. Each class's \"probability\" will be returned.\n",
    "\n",
    "For more information, see [Raschka's explaination in the mlxtend library.](http://rasbt.github.io/mlxtend/user_guide/classifier/SoftmaxRegression/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iX = load_iris()['data']\n",
    "iy = load_iris()['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> iris is a 3-class problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(iy).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def generate_estimates(xtrain, ytrain):\n",
    "    modeling_pipeline = Pipeline([\n",
    "        ('data_processing', StandardScaler()),\n",
    "        ('logreg', LogisticRegression(penalty=None))]\n",
    "    )\n",
    "\n",
    "    return modeling_pipeline.fit(xtrain, ytrain)\n",
    "\n",
    "iX_train, iX_test, iy_train, iy_test = train_test_split(iX, iy)\n",
    "\n",
    "# We could do this in the pipeline 4 features to 2 features\n",
    "pca = PCA(n_components=2)\n",
    "iX_train = pca.fit_transform(iX_train)\n",
    "iX_test = pca.transform(iX_test)  # <== this is transform\n",
    "\n",
    "irisModel = generate_estimates(iX_train, iy_train)\n",
    "irisModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihats = irisModel.predict_proba(iX_test)\n",
    "ihats_d = irisModel.predict(iX_test)\n",
    "\n",
    "ihats[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Each sample gets a \"probability\" for being in the indicated class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihats[:5, :].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> They are normalized so the probabilities for each of the 3 classes sum to 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code is from [Page 34 of Python Machine Learning 3rd Edition, Raschka](https://github.com/rasbt/python-machine-learning-book-3rd-edition/blob/master/ch02/ch02.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "    \n",
    "    # plot class examples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=cl, \n",
    "#                     edgecolor='black'\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can visualize the decision boundaries because we restricted the model to only contain 2 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(iX_train, iy_train, irisModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't perfectly separate the classes in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(iX_test, iy_test, irisModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we see the same misclassification in the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for Evaluating Multiclass\n",
    "Same basic metrics, but can calculate on a micro or macro basis. As an example:\n",
    "\n",
    "## Precision - Micro\n",
    "Weights all **examples** equally.\n",
    "\n",
    "$$PRE_{micro} = \\frac{TP_{1}+\\dots+TP_{k}}{TP_{1}+\\dots+TP_{k} + FP_{1}+\\dots+FP_{k}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision_recall_fscore_support(iy_test, ihats_d, average='micro')[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Precision - Macro\n",
    "Weights all **classes** equally.\n",
    "\n",
    "$$\\frac{PRE_{1}+\\dots+PRE_{k}}{k}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(iy_test, ihats_d, average='macro')[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "iris['data'][:5,:]\n",
    "\n",
    "y = np.where(iris['target'] == 2, 1, 0)\n",
    "X = iris['data']\n",
    "\n",
    "const = np.ones(shape=y.shape).reshape(-1,1)\n",
    "\n",
    "mat = np.concatenate( (const, X), axis=1)\n",
    "mat[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall the algorithm we created for gradient descent for linear regression\n",
    "Using the following cost function:\n",
    "$$J(w)=\\frac{1}{2}\\sum(y^{(i)} - \\hat{y}^{(i)})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradientDescent(x, y, theta, alpha, m, numIterations):\n",
    "    thetaHistory = list()\n",
    "    \n",
    "    xTrans = x.transpose()\n",
    "    costList = list()\n",
    "    \n",
    "    for i in range(0, numIterations):\n",
    "        # data x feature weights = y_hat\n",
    "        hypothesis = np.dot(x, theta)\n",
    "        # how far we are off\n",
    "        loss = hypothesis - y \n",
    "        # mse\n",
    "        cost = np.sum(loss ** 2) / (2 * m)\n",
    "        costList.append(cost)\n",
    "\n",
    "        # avg gradient per example\n",
    "        gradient = np.dot(xTrans, loss) / m \n",
    "\n",
    "        # update\n",
    "        theta = theta - alpha * gradient\n",
    "        thetaHistory.append(theta)\n",
    "        \n",
    "    return thetaHistory, costList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Logistic regression we replace with our likehihood function:\n",
    "\n",
    "$$\n",
    "J(w)=\\sum{[-y^{(i)}log(\\theta(z^{(i)}))-(1-y^{(i)})log(1-\\theta(z^{(i)})]}\n",
    "$$\n",
    "\n",
    "## And add the sigmoid function to bound $y$ between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(x, y, alpha, numIterations):\n",
    "    def mle(y,yhat):\n",
    "        '''\n",
    "        This replaces the mean squared error\n",
    "        '''\n",
    "        return (-y.dot(np.log(yhat)) - ((1-y)).dot(np.log(1-yhat)))\n",
    "    \n",
    "    def sigmoid(z):\n",
    "        '''\n",
    "        Transforms values to follow the sigmoid function and bound between 0 and 1\n",
    "        '''\n",
    "        return 1./(1. + np.exp(-np.clip(z, -250, 250)))\n",
    "    \n",
    "    # number of examples in the training data\n",
    "    m = x.shape[0]\n",
    "\n",
    "    # initialize weights to small random numbers\n",
    "    theta = np.random.normal(loc=0.0, scale=0.1, size=x.shape[1])\n",
    "    \n",
    "    # history of theta values\n",
    "    thetaHistory = list()\n",
    "    \n",
    "    xTrans = x.transpose()\n",
    "    \n",
    "    # history of cost values\n",
    "    costList = list()\n",
    "    \n",
    "    for i in range(0, numIterations):\n",
    "        \n",
    "        # predicted value based on feature matrix and current weights\n",
    "        hypothesis = np.dot(x, theta)\n",
    "        \n",
    "        # sigmoid transformation so we have bounded values\n",
    "        hypothesis = sigmoid(hypothesis)\n",
    "        \n",
    "        # how far we are off from the actual value\n",
    "        loss = hypothesis - y \n",
    "        \n",
    "        # determine cost based on the log likehilood function\n",
    "        cost = mle(y, hypothesis)\n",
    "        costList.append(cost)\n",
    "\n",
    "        # avg gradient per example\n",
    "        gradient = np.dot(xTrans, loss) / m \n",
    "\n",
    "        # update the weights\n",
    "        theta = theta - alpha * gradient\n",
    "        thetaHistory.append(theta)\n",
    "        \n",
    "    return thetaHistory, costList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try it out\n",
    "- Run the algorithm, which gives us the weight and cost history. \n",
    "- Plot the cost to see if it converges.  \n",
    "- Make predictions with the last batch of weights.  \n",
    "- Apply the sigmoid function to the above predictions.  \n",
    "- Plot the actual vs. predicted values.  \n",
    "- Plot the evolution of the weights for each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 500000\n",
    "\n",
    "import datetime\n",
    "\n",
    "start_ts = datetime.datetime.now()\n",
    "betaHistory, costList = gradientDescent(mat, y, alpha=0.01, numIterations=iters)\n",
    "                                                                 \n",
    "end_ts = datetime.datetime.now()\n",
    "\n",
    "print(f'Completed in {end_ts-start_ts}')\n",
    "\n",
    "# cost history\n",
    "plt.plot(costList)\n",
    "plt.title(f'Final cost: {costList[-1]:,.2f}', loc='left')\n",
    "plt.show()\n",
    "\n",
    "# predict history\n",
    "gs_betas = betaHistory[iters-1]\n",
    "gs_predictions = np.dot(mat, gs_betas)\n",
    "\n",
    "# we need to apply the sigmoid/activation function to bound the predictions between (0,1)\n",
    "gs_predictions = 1./(1+np.exp(-gs_predictions))\n",
    "\n",
    "plt.plot(y, gs_predictions, 'bo', alpha=0.2)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Gradient Descent Regression Fit on Training Data')\n",
    "plt.show()\n",
    "\n",
    "from collections import defaultdict\n",
    "thetas = defaultdict(list)\n",
    "\n",
    "for i in range(len(betaHistory)):\n",
    "    for j in range(len(betaHistory[i])):\n",
    "        thetas[j].append(betaHistory[i][j])\n",
    "        \n",
    "thetasD = pd.DataFrame.from_dict(thetas) \n",
    "thetasD.plot(legend=False)\n",
    "plt.title('Beta Estimates')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see the loss is decreasing over the iterations.  \n",
    "- Predictions are bounded between 0 and 1 because of the sigmoid function.  \n",
    "- Weights update after each iteration and will eventually stabilize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readings\n",
    "\n",
    "- [Logistic Regression Youtube Demo](https://www.youtube.com/watch?v=71iXeuKFcQM)  \n",
    "- [scikit-learn Logistic Regression](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression)  \n",
    "- [Logistic Regression Wikipedia](https://en.wikipedia.org/wiki/Logistic_regression) \n",
    "- [Ben Taskar’s Notes](https://web.archive.org/web/20151026065954/http://learning.cis.upenn.edu/cis520_fall2009/index.php?n=Lectures.Logistic)  \n",
    "- [Cornell class CS4780](https://www.youtube.com/watch?v=GnkDzIOxfzI&list=PLl8OlHZGYOQ7bkVbuRthEsaLr7bONzbXS&index=12)  \n",
    "- [Python Machine Learning (Raschka) - Chapter 3](https://github.com/rasbt/python-machine-learning-book-3rd-edition/blob/master/ch03/ch03.ipynb)  \n",
    "- [Hands-on Machine Learning with Scikit-Learn, Keras & TensorFlow (Geron) - Chaper 4](https://github.com/ageron/handson-ml2/blob/master/04_training_linear_models.ipynb)   \n",
    "- [Softmax Regression for multiclass problems](http://rasbt.github.io/mlxtend/user_guide/classifier/SoftmaxRegression/)  \n",
    "- [Logistic Regression: From Introductory to Advanced Concepts and Applications](https://methods.sagepub.com/book/logistic-regression-from-introductory-to-advanced-concepts-and-applications)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
